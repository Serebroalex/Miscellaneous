{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20011981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1e9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    \"\"\"\n",
    "    Linear transformation neural layer.\n",
    "    \n",
    "    Args:\n",
    "    - n_in (int): Input dimension.\n",
    "    - n_out (int): Output dimension.\n",
    "    - bias (bool, optional): Whether to include bias terms. Default is True.\n",
    "    \n",
    "    Attributes:\n",
    "    - weight (torch.Tensor): Learnable weight matrix of shape (n_in, n_out).\n",
    "    - bias (torch.Tensor or None): Learnable bias vector of shape (n_out) if bias is True, otherwise None.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__(self, n_in, n_out, bias=True): Initializes the Linear layer with Kaiming initialization.\n",
    "    - __call__(self, x): Computes the linear transformation of the input tensor x.\n",
    "    - parameters(self): Returns a list of learnable parameters (weight and bias if applicable).\n",
    "    \n",
    "    Returns:\n",
    "    - out (torch.Tensor): Linearly transformed output of shape (m, n_out).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, n_out, bias = True):\n",
    "        self.weight = torch.randn((n_in, n_out)) / n_in**.5 # Kaiming initialisation\n",
    "        self.bias = torch.zeros(n_out) if bias else None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight \n",
    "        \n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "            \n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "class Flatten:\n",
    "    \"\"\"\n",
    "    Flatten layer.\n",
    "    \n",
    "    Args:\n",
    "    - x (torch.Tensor): Input tensor of shape (m, n_c, n_h, n_w).\n",
    "    \n",
    "    Methods:\n",
    "    - __call__(self, x): Flattens the input tensor x.\n",
    "    - parameters(self): Returns an empty list since there are no learnable parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - out (torch.Tensor): Flattened output of shape (m, n_c * n_h * n_w).\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = x.reshape(x.shape[0], -1)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class ZeroPad:\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset x. The padding is applied to the height and width of each image.\n",
    "    \n",
    "    Args:\n",
    "    - pad (int): Amount of padding around each image on the vertical and horizontal dimensions.\n",
    "    - x (torch.Tensor): Input tensor of shape (m, n_c, n_h, n_w), representing a batch of m images.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__(self, pad): Initializes the ZeroPad layer with the specified padding.\n",
    "    - __call__(self, x): Applies zero padding to the input batch of images x.\n",
    "    - parameters(self): Returns an empty list since there are no learnable parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - X_pad (torch.Tensor): Padded images of shape (m, n_c, n_h + 2 * pad, n_w + 2 * pad).\n",
    "    \"\"\"\n",
    "    def __init__(self, pad):\n",
    "        self.padding = pad\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \n",
    "        m, n_c, n_h, n_w = x.size()\n",
    "        X_pad = torch.zeros([m, n_c, n_h + 2 * self.padding, n_w + 2 * self.padding])\n",
    "        X_pad[:,:, self.padding : self.padding + n_h, self.padding: self.padding + n_w] = x\n",
    "        \n",
    "        return X_pad  \n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "\n",
    "class Convolution2D:\n",
    "    \"\"\"\n",
    "    Convolutional neural layer.\n",
    "    \n",
    "    Args:\n",
    "    - n_c_prev (int): Number of input channels.\n",
    "    - n_c (int): Number of output channels (filters).\n",
    "    - f (int): Kernel size (filter size).\n",
    "    - stride (int, optional): Stride for the convolution operation. Default is 1.\n",
    "    - bias (bool, optional): Whether to include bias terms. Default is True.\n",
    "    - X (torch.Tensor): Input tensor of shape (m, n_c_prev, n_h_prev, n_w_prev).\n",
    "    \n",
    "    Attributes:\n",
    "    - n_c_prev (int): Number of input channels.\n",
    "    - n_c (int): Number of output channels (filters).\n",
    "    - f (int): Kernel size (filter size).\n",
    "    - stride (int): Stride for the convolution operation.\n",
    "    - weight (torch.Tensor): Learnable weight tensor of shape (n_c, n_c_prev, f, f).\n",
    "    - bias (torch.Tensor or None): Learnable bias tensor of shape (n_c, 1, 1, 1) if bias is True, otherwise None.\n",
    "    \n",
    "    Methods:\n",
    "    - __init__(self, n_c_prev, n_c, f, stride=1, bias=True): Initializes the Convolution2D layer with Kaiming initialization.\n",
    "    - __call__(self, X): Performs convolution on the input tensor X.\n",
    "    - parameters(self): Returns a list of learnable parameters (weight and bias if applicable).\n",
    "    \n",
    "    Returns:\n",
    "    - Z (torch.Tensor): Convolved output of shape (m, n_c, (n_h_prev - f) // stride + 1, (n_w_prev - f) // stride + 1).\n",
    "    \"\"\"\n",
    "    def __init__(self, n_c_prev, n_c, f, stride = 1, bias = True):\n",
    "        self.n_c_prev = n_c_prev\n",
    "        self.n_c = n_c\n",
    "        self.f = f\n",
    "        self.stride = stride\n",
    "        self.weight = torch.randn((n_c, n_c_prev, f, f)) / n_c_prev**.5 # Kaiming initialisation\n",
    "        self.bias = torch.zeros((n_c, 1, 1, 1)) if bias else None\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \n",
    "        # Get the input shape.\n",
    "        m, _, n_h_prev, n_w_prev = X.size()\n",
    "        \n",
    "        # Compute the height and width dimensions of the output.\n",
    "        n_h = int((n_h_prev - self.f) / self.stride + 1)\n",
    "        n_w = int((n_w_prev - self.f) / self.stride + 1)\n",
    "        \n",
    "        # Initialise the output tensor.\n",
    "        Z = torch.zeros(m, self.n_c, n_h, n_w)\n",
    "        \n",
    "        # Loop over the batch of training examples to fill the output tensor Z.\n",
    "        for i in range(m):\n",
    "            # Loop over vertical axis of the output volume.\n",
    "            for h in range(n_h):           \n",
    "                #Find the vertical start and end of the current \"slice\".\n",
    "                vert_start = h * self.stride\n",
    "                vert_end = vert_start + self.f\n",
    "                # Loop over horizontal axis of the output volume.\n",
    "                for w in range(n_w):\n",
    "                    #Find the horizontal start and end of the current \"slice\".\n",
    "                    horiz_start = w * self.stride\n",
    "                    horiz_end = horiz_start + self.f\n",
    "                    # Loop over channels (= #filters) of the output volume.\n",
    "                    for c in range(self.n_c):\n",
    "                        # Use the corners to define the (3D) slice of the ith training example.\n",
    "                        X_slice = X[i, :, vert_start : vert_end, horiz_start : horiz_end] # (n_c_prev, f, f)\n",
    "                        #Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron.\n",
    "                        Z[i, c, h, w] = torch.sum(X_slice * self.weight[c, :, :, :]) + torch.squeeze(self.bias[c, :, :, :])\n",
    "        return Z\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "    \n",
    "class Pooling:\n",
    "    \"\"\"\n",
    "    Pooling neural layer.\n",
    "    \n",
    "    Args:\n",
    "    - f (int): Kernel size (pooling window size).\n",
    "    - stride (int, optional): Stride for the pooling operation. Default is 1.\n",
    "    - mode (str, optional): Pooling mode, either \"max\" or \"average\". Default is \"max\".\n",
    "    - X (torch.Tensor): Input tensor of shape (m, n_c, n_h_prev, n_w_prev).\n",
    "    \n",
    "    Methods:\n",
    "    - __init__(self, f, stride=1, mode=\"max\"): Initializes the Pooling layer.\n",
    "    - __call__(self, X): Applies pooling to the input tensor X.\n",
    "    - parameters(self): Returns an empty list since there are no learnable parameters.\n",
    "    \n",
    "    Returns:\n",
    "    - A (torch.Tensor): Pooled output of shape (m, n_c, (n_h_prev - f) // stride + 1, (n_w_prev - f) // stride + 1).\n",
    "    \"\"\"\n",
    "    def __init__(self, f, stride = 1, mode = \"max\"):\n",
    "        self.f = f\n",
    "        self.stride = stride\n",
    "        self.mode = mode\n",
    "        assert mode == \"max\" or mode == \"average\", 'mode must be either \"max\" or \"average\".'\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        \n",
    "        # Get the input shape. \n",
    "        m, n_c, n_h_prev, n_w_prev = X.size()\n",
    "        \n",
    "        # Compute the height and width dimensions of the output.\n",
    "        n_h = int((n_h_prev - self.f) / self.stride + 1)\n",
    "        n_w = int((n_w_prev - self.f) / self.stride + 1)\n",
    "        \n",
    "        # Initialise the output tensor.\n",
    "        A = torch.zeros(m, n_c, n_h, n_w)\n",
    "        \n",
    "        # Loop over the batch of training examples to fill the output tensor A\n",
    "        for i in range(m):\n",
    "            # Loop over vertical axis of the output volume\n",
    "            for h in range(n_h):           \n",
    "                #Find the vertical start and end of the current \"slice\"\n",
    "                vert_start = h * self.stride\n",
    "                vert_end = vert_start + self.f\n",
    "                # Loop over horizontal axis of the output volume.\n",
    "                for w in range(n_w):\n",
    "                    #Find the horizontal start and end of the current \"slice\".\n",
    "                    horiz_start = w * self.stride\n",
    "                    horiz_end = horiz_start + self.f\n",
    "                    # Loop over channels (= #filters) of the output volume.\n",
    "                    for c in range(n_c):\n",
    "                        # Use the corners to define the (3D) slice of the ith training example.\n",
    "                        X_slice = X[i, :, vert_start : vert_end, horiz_start : horiz_end] # (n_c, f, f)\n",
    "                        # Compute the pooling operation on the slice. \n",
    "                        # Use an if statement to differentiate the modes. \n",
    "                        if self.mode == \"max\":\n",
    "                            A[i, c, h, w] = torch.max(X_slice)\n",
    "                        elif self.mode == \"average\":\n",
    "                            A[i, c, h, w] = torch.mean(X_slice)\n",
    "        return A\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class ReLU:\n",
    "    \"\"\"\n",
    "    Rectified Linear Unit (ReLU) activation layer.\n",
    "    \n",
    "    Methods:\n",
    "    - __call__(self, x): Applies ReLU activation to the input tensor x.\n",
    "    - parameters(self): Returns an empty list since there are no learnable parameters.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = x * (x > 0).float()\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Sigmoid:\n",
    "    \"\"\"\n",
    "    Sigmoid activation layer.\n",
    "    \n",
    "    Methods:\n",
    "    - __call__(self, x): Applies the sigmoid activation function to the input tensor x.\n",
    "    - parameters(self): Returns an empty list since there are no learnable parameters.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        self.out = 1 / (1 + torch.exp(-x))\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "\n",
    "class Sequential:\n",
    "    \"\"\"\n",
    "    Container for organizing and applying a sequence of neural network layers.\n",
    "\n",
    "    Args:\n",
    "    - layers (list): List of layer instances to be added to the sequential model.\n",
    "\n",
    "    Methods:\n",
    "    - __init__(self, layers): Initializes the Sequential model with a list of layers.\n",
    "    - __repr__(self): Returns a string representation of the Sequential model, including the number of layers and parameters.\n",
    "    - __call__(self, x, verbose=False): Applies each layer in sequence to the input tensor x.\n",
    "    - add(self, layer): Adds a new layer to the Sequential model.\n",
    "    - parameters(self): Returns a list of all learnable parameters in the model.\n",
    "\n",
    "    Attributes:\n",
    "    - layers (list): List of layers in the Sequential model.\n",
    "    - out (torch.Tensor): Output tensor after applying all layers in the sequence.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Sequential model, number of layers: {len(self.layers)}, number of parameters: {sum([p.numel() for layer in self.layers for p in layer.parameters()])}'\n",
    "    \n",
    "    def __call__(self, x, verbose = False):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            if verbose:\n",
    "                print(x.size())\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b9cab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential model, number of layers: 13, number of parameters: 1022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<__main__.ZeroPad at 0x7f93683beee0>,\n",
       " <__main__.Convolution2D at 0x7f9310323e20>,\n",
       " <__main__.ReLU at 0x7f93103232e0>,\n",
       " <__main__.ZeroPad at 0x7f9310323340>,\n",
       " <__main__.Pooling at 0x7f9310323610>,\n",
       " <__main__.ZeroPad at 0x7f9310323520>,\n",
       " <__main__.Convolution2D at 0x7f9310323a90>,\n",
       " <__main__.ReLU at 0x7f9310323d60>,\n",
       " <__main__.ZeroPad at 0x7f9310323d30>,\n",
       " <__main__.Pooling at 0x7f93103237f0>,\n",
       " <__main__.Flatten at 0x7f9310323280>,\n",
       " <__main__.Linear at 0x7f93103234f0>,\n",
       " <__main__.Sigmoid at 0x7f9310323400>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(1)\n",
    "\n",
    "f1 = 4\n",
    "f2 = 8\n",
    "f3 = 2\n",
    "f4 = 4\n",
    "\n",
    "stride1 = 1\n",
    "stride2 = 8\n",
    "stride3 = 1\n",
    "stride4 = 6\n",
    "\n",
    "n_c0 = 3\n",
    "n_c1 = 8\n",
    "n_c2 = 16\n",
    "\n",
    "pad1 = (f1 - 1) // 2\n",
    "pad2 = (f2 - 1) // 2\n",
    "pad3 = (f3 - 1) // 2\n",
    "pad4 = (f4 - 1) // 2\n",
    "\n",
    "m = 1\n",
    "n_h0 = 64\n",
    "n_w0 = 64\n",
    "n_out = 6\n",
    "\n",
    "model = Sequential([ZeroPad(pad1),\n",
    "                    Convolution2D(n_c_prev = n_c0, n_c = n_c1, f = f1, stride = stride1),\n",
    "                    ReLU(),\n",
    "                    ZeroPad(pad2),\n",
    "                    Pooling(f2, stride2),\n",
    "                    ZeroPad(pad3),\n",
    "                    Convolution2D(n_c_prev = n_c1, n_c = n_c2, f = f3, stride = stride3),\n",
    "                    ReLU(),\n",
    "                    ZeroPad(pad4),\n",
    "                    Pooling(f4, stride4),\n",
    "                    Flatten(),\n",
    "                    Linear(n_c2, n_out),\n",
    "                    Sigmoid()\n",
    "                   ])\n",
    "\n",
    "for p in model.parameters(): \n",
    "    p.requires_grad = True\n",
    "\n",
    "print(model)\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ec80b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n",
      "torch.Size([1, 3, 66, 66])\n",
      "torch.Size([1, 8, 63, 63])\n",
      "torch.Size([1, 8, 63, 63])\n",
      "torch.Size([1, 8, 69, 69])\n",
      "torch.Size([1, 8, 8, 8])\n",
      "torch.Size([1, 8, 8, 8])\n",
      "torch.Size([1, 16, 7, 7])\n",
      "torch.Size([1, 16, 7, 7])\n",
      "torch.Size([1, 16, 9, 9])\n",
      "torch.Size([1, 16, 1, 1])\n",
      "torch.Size([1, 16])\n",
      "torch.Size([1, 6])\n",
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(m, n_c0, n_h0, n_w0)\n",
    "print(X.size())\n",
    "out = model(X, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
